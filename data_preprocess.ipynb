{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import mean, col, udf\n",
    "from pyspark import SQLContext, SparkContext\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String map setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set interface of pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python\\lib\\site-packages\\pyspark\\sql\\context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Enter = SparkContext('local')\n",
    "sqlContext = SQLContext(Enter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = sqlContext.read.csv('data/train.csv', sep='\\t', header=True)\n",
    "testdata = sqlContext.read.csv('data/test.csv', sep='\\t', header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(fea):\n",
    "    global traindata, testdata\n",
    "    ans = {}\n",
    "    dummy = []\n",
    "\n",
    "    for i in traindata.select(fea).distinct().collect():\n",
    "        dummy.append(traindata[fea])\n",
    "    for i in testdata.select(fea).distinct().collect():\n",
    "        dummy.append(testdata[fea])\n",
    "\n",
    "    testdata = testdata.drop('Step Start Time')\n",
    "    traindata = traindata.drop('Step Start Time')\n",
    "\n",
    "    testdata = testdata.drop('First Transaction Time')\n",
    "    traindata = traindata.drop('First Transaction Time')\n",
    "\n",
    "    testdata = testdata.drop('Correct Transaction Time')\n",
    "    traindata = traindata.drop('Correct Transaction Time')\n",
    "\n",
    "    testdata = testdata.drop('Step End Time')\n",
    "    traindata = traindata.drop('Step End Time')\n",
    "\n",
    "    testdata = testdata.drop('Step Duration (sec)')\n",
    "    traindata = traindata.drop('Step Duration (sec)')\n",
    "\n",
    "    testdata = testdata.drop('Correct Step Duration (sec)')\n",
    "    traindata = traindata.drop('Correct Step Duration (sec)')\n",
    "\n",
    "    testdata = testdata.drop('Error Step Duration (sec)')\n",
    "    traindata = traindata.drop('Error Step Duration (sec)')\n",
    "\n",
    "    testdata = testdata.drop('Incorrects')\n",
    "    traindata = traindata.drop('Incorrects')\n",
    "\n",
    "    testdata = testdata.drop('Hints')\n",
    "    traindata = traindata.drop('Hints')\n",
    "\n",
    "    testdata = testdata.drop('Corrects')\n",
    "    traindata = traindata.drop('Corrects')\n",
    "\n",
    "    cols = [i[fea]\n",
    "            for i in traindata.union(testdata).select(fea).distinct().collect()]\n",
    "    for index, sid in enumerate(cols):\n",
    "        ans[sid] = index\n",
    "\n",
    "    traindata = traindata.withColumn(fea, ans[traindata[fea]])\n",
    "    testdata = testdata.withColumn(fea, ans[testdata[fea]])\n",
    "\n",
    "def right_train():\n",
    "    global traindata\n",
    "    correct = traindata.filter(traindata['Correct First Attempt'] == '1')\n",
    "\n",
    "def right_test():\n",
    "    global testdata\n",
    "    correct = testdata.filter(testdata['Correct First Attempt'] == '1')\n",
    "\n",
    "def cal_rate_train(fea):\n",
    "    global traindata, testdata\n",
    "    col = traindata.groupby(fea).count()\n",
    "    right = right_train().groupby(fea).count()\n",
    "\n",
    "    rate = right.join(col, col[fea] == right[fea]).drop(col[fea]).select(fea,(right['count'] / col['count']))\n",
    "    traindata = traindata.join(rate, rate[fea] == traindata[fea]).drop(rate[fea])\n",
    "    testdata = testdata.join(rate, rate[fea] == testdata[fea]).drop(rate[fea])\n",
    "\n",
    "def cal_rate_test(fea):\n",
    "    global traindata, testdata\n",
    "    col = testdata.groupby(fea).count()\n",
    "    right = right_test().groupby(fea).count()\n",
    "    \n",
    "    rate = right.join(col, col[fea] == right[fea]).drop(col[fea]).select(fea,(right['count'] / col['count']))\n",
    "    traindata = traindata.join(rate, rate[fea] == traindata[fea]).drop(rate[fea])\n",
    "    testdata = testdata.join(rate, rate[fea] == testdata[fea]).drop(rate[fea])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train data first round process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(7,15):\n",
    "#     preprocess(traindata[i])\n",
    "#     preprocess(testdata[i])\n",
    "\n",
    "with open(\"data/train.csv\",newline = '') as f, open(\"data/first_pro.csv\",'a+',newline='') as rf:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    writ = csv.writer(rf)\n",
    "    for row in reader: \n",
    "        writ.writerow(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train data pre-process code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/first_pro.csv\")\n",
    "len_col = len(df['KC(Default)'])\n",
    "index_tail = len_col\n",
    "for i in range(0,len_col):\n",
    "    if(type(df['KC(Default)'][i]) == type('a')):\n",
    "        str_kc = df['KC(Default)'][i].split('~~')\n",
    "        str_opp = df['Opportunity(Default)'][i].split('~~')\n",
    "        lenko = len(str_kc)\n",
    "        if(lenko > 1):\n",
    "            for j in range(0,lenko):\n",
    "                if j == 0:\n",
    "                    df.loc[i,'KC(Default)'] = str_kc[0]\n",
    "                    df.loc[i,'Opportunity(Default)'] = str_opp[0]\n",
    "                    change_row = df.loc[i]\n",
    "                else:\n",
    "                    change_row[17] = str_kc[j]\n",
    "                    change_row[18] = str_opp[j]\n",
    "                    df.loc[index_tail] = change_row\n",
    "                    index_tail += 1\n",
    "df.to_csv(\"data/train_index.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/first_pro.csv\")\n",
    "len_col = len(df['KC(Default)'])\n",
    "index_tail = len_col\n",
    "for i in range(0,len_col):\n",
    "    if(type(df['KC(Default)'][i]) == type('a')):\n",
    "        str_kc = df['KC(Default)'][i].split('~~')\n",
    "        str_opp = df['Opportunity(Default)'][i].split('~~')\n",
    "        lenko = len(str_kc)\n",
    "        if(lenko > 1):\n",
    "            for j in range(0,lenko):\n",
    "                if j == 0:\n",
    "                    df.loc[i,'KC(Default)'] = str_kc[0]\n",
    "                    df.loc[i,'Opportunity(Default)'] = str_opp[0]\n",
    "                    change_row = df.loc[i]\n",
    "                else:\n",
    "                    change_row[17] = str_kc[j]\n",
    "                    change_row[18] = str_opp[j]\n",
    "                    df.loc[index_tail] = change_row\n",
    "                    index_tail += 1\n",
    "df[\"KC(Default)\"] = encoder.fit_transform(df[\"KC(Default)\"])\n",
    "df[\"Step Name\"] = encoder.fit_transform(df[\"Step Name\"])\n",
    "df[\"Anon Student Id\"] = encoder.fit_transform(df[\"Anon Student Id\"])\n",
    "df[\"Problem Hierarchy\"] = encoder.fit_transform(df[\"Problem Hierarchy\"])\n",
    "df[\"Problem Name\"] = encoder.fit_transform(df[\"Problem Name\"])\n",
    "df.to_csv(\"data/map_train_index.csv\",index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data first round process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(7,15):\n",
    "#     preprocess(traindata[i])\n",
    "#     preprocess(testdata[i])\n",
    "\n",
    "with open(\"data/test.csv\",newline = '') as f, open(\"data/first_pro_test.csv\",'a+',newline='') as rf:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    writ = csv.writer(rf)\n",
    "    for row in reader: \n",
    "        writ.writerow(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data pre-process code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/first_pro_test.csv\")\n",
    "len_col = len(df['KC(Default)'])\n",
    "index_tail = len_col\n",
    "for i in range(0,len_col):\n",
    "    if(type(df['KC(Default)'][i]) == type('a')):\n",
    "        str_kc = df['KC(Default)'][i].split('~~')\n",
    "        str_opp = df['Opportunity(Default)'][i].split('~~')\n",
    "        lenko = len(str_kc)\n",
    "        if(lenko > 1):\n",
    "            for j in range(0,lenko):\n",
    "                if j == 0:\n",
    "                    df.loc[i,'KC(Default)'] = str_kc[0]\n",
    "                    df.loc[i,'Opportunity(Default)'] = str_opp[0]\n",
    "                    change_row = df.loc[i]\n",
    "                else:\n",
    "                    change_row[17] = str_kc[j]\n",
    "                    change_row[18] = str_opp[j]\n",
    "                    df.loc[index_tail] = change_row\n",
    "                    index_tail += 1\n",
    "df.to_csv(\"data/test_index.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/first_pro_test.csv\")\n",
    "len_col = len(df['KC(Default)'])\n",
    "index_tail = len_col\n",
    "for i in range(0,len_col):\n",
    "    if(type(df['KC(Default)'][i]) == type('a')):\n",
    "        str_kc = df['KC(Default)'][i].split('~~')\n",
    "        str_opp = df['Opportunity(Default)'][i].split('~~')\n",
    "        lenko = len(str_kc)\n",
    "        if(lenko > 1):\n",
    "            for j in range(0,lenko):\n",
    "                if j == 0:\n",
    "                    df.loc[i,'KC(Default)'] = str_kc[0]\n",
    "                    df.loc[i,'Opportunity(Default)'] = str_opp[0]\n",
    "                    change_row = df.loc[i]\n",
    "                else:\n",
    "                    change_row[17] = str_kc[j]\n",
    "                    change_row[18] = str_opp[j]\n",
    "                    df.loc[index_tail] = change_row\n",
    "                    index_tail += 1\n",
    "df[\"KC(Default)\"] = encoder.fit_transform(df[\"KC(Default)\"])\n",
    "df[\"Step Name\"] = encoder.fit_transform(df[\"Step Name\"])\n",
    "df[\"Anon Student Id\"] = encoder.fit_transform(df[\"Anon Student Id\"])\n",
    "df[\"Problem Hierarchy\"] = encoder.fit_transform(df[\"Problem Hierarchy\"])\n",
    "df[\"Problem Name\"] = encoder.fit_transform(df[\"Problem Name\"])\n",
    "df.to_csv(\"data/map_test_index.csv\",index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulate NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepath = 'data/train_index.csv'\n",
    "rd = pd.read_csv(train_filepath)\n",
    "traindata = pd.DataFrame(rd)\n",
    "\n",
    "test_filepath = 'data/test_index.csv'\n",
    "test_f = pd.read_csv(test_filepath)\n",
    "testdata = pd.DataFrame(test_f)\n",
    "\n",
    "for i in range(0, len(traindata['KC(Default)'])):\n",
    "    if (type(traindata['KC(Default)'][i]) != type('a')):\n",
    "        traindata['KC(Default)'][i] = -1\n",
    "traindata.to_csv('data/train_select_str.csv')\n",
    "\n",
    "for i in range(0, len(testdata['KC(Default)'])):\n",
    "    if (type(testdata['KC(Default)'][i]) != type('a')):\n",
    "        testdata['KC(Default)'][i] = -1\n",
    "\n",
    "csv_path = 'data/test_select_str.csv'\n",
    "df_new = testdata\n",
    "x = np.array(testdata['Correct First Attempt'])\n",
    "for i in range(0, len(x)):\n",
    "    if math.isnan(x[i]):\n",
    "        df_new = df_new.drop([i],axis=0)\n",
    "df_new_cpy = df_new['Correct First Attempt']\n",
    "df_new.to_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepath = 'data/map_train_index.csv'\n",
    "rd = pd.read_csv(train_filepath)\n",
    "traindata = pd.DataFrame(rd)\n",
    "\n",
    "test_filepath = 'data/map_test_index.csv'\n",
    "test_f = pd.read_csv(test_filepath)\n",
    "testdata = pd.DataFrame(test_f)\n",
    "\n",
    "for i in range(0, len(traindata['KC(Default)'])):\n",
    "    if (type(traindata['KC(Default)'][i]) != type('a')):\n",
    "        traindata['KC(Default)'][i] = -1\n",
    "traindata.to_csv('data/train_select.csv')\n",
    "\n",
    "for i in range(0, len(testdata['KC(Default)'])):\n",
    "    if (type(testdata['KC(Default)'][i]) != type('a')):\n",
    "        testdata['KC(Default)'][i] = -1\n",
    "\n",
    "csv_path = 'data/test_select.csv'\n",
    "df_new = testdata\n",
    "x = np.array(testdata['Correct First Attempt'])\n",
    "for i in range(0, len(x)):\n",
    "    if math.isnan(x[i]):\n",
    "        df_new = df_new.drop([i],axis=0)\n",
    "df_new_cpy = df_new['Correct First Attempt']\n",
    "df_new.to_csv(csv_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single feature manipulate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_conv_s(data,pca,leng):\n",
    "    a = np.array(data)\n",
    "    b = np.unique(a)\n",
    "    ans = {}\n",
    "    rate = []\n",
    "    for i in range(0,len(b)):\n",
    "        dummy = [0,0,0]\n",
    "        ans.setdefault(b[i],dummy)\n",
    "    for i in range(0,leng):\n",
    "        ans[data[i]][0] += 1\n",
    "        if(pca[i] == 1):\n",
    "            ans[data[i]][1] += 1\n",
    "    for v in ans.values():\n",
    "        v[2] = round(v[1] / v[0],5)\n",
    "    for i in range(0,leng):\n",
    "        rate.append(ans[data[i]][2])\n",
    "    return rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple features manipulate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_conv_d(data1,data2,pca,leng):\n",
    "    ans = {}\n",
    "    rate = []\n",
    "    for i in range(0,leng):\n",
    "        zero = [0,0,0]\n",
    "        dummy = (data1[i],data2[i])\n",
    "        if(dummy not in ans):\n",
    "            ans.setdefault(dummy,zero)\n",
    "    for i in range(0,leng):\n",
    "        ans[(data1[i],data2[i])][0] += 1\n",
    "        if(pca[i] == 1):\n",
    "            ans[(data1[i],data2[i])][1] += 1\n",
    "    for v in ans.values():\n",
    "        v[2] = round(v[1] / v[0],5)\n",
    "    for i in range(0,leng):\n",
    "        rate.append(ans[(data1[i],data2[i])][2])\n",
    "    return rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train additional feature generation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train_select.csv\")\n",
    "\n",
    "sid = df[\"Anon Student Id\"]\n",
    "p_name = df[\"Problem Name\"]\n",
    "p_hier = df[\"Problem Hierarchy\"]\n",
    "s_name = df[\"Step Name\"]\n",
    "kc = df[\"KC(Default)\"]\n",
    "pca = df[\"Correct First Attempt\"]\n",
    "\n",
    "arr_leng = len(sid)\n",
    "arr1 = rate_conv_s(sid,pca,arr_leng)\n",
    "arr2 = rate_conv_s(p_name,pca,arr_leng)\n",
    "arr3 = rate_conv_s(s_name,pca,arr_leng)\n",
    "arr4 = rate_conv_s(kc,pca,arr_leng)\n",
    "arr5 = rate_conv_s(p_hier,pca,arr_leng)\n",
    "arr6 = rate_conv_d(sid,kc,pca,arr_leng)\n",
    "arr7 = rate_conv_d(sid,p_name,pca,arr_leng)\n",
    "arr8 = rate_conv_d(sid,s_name,pca,arr_leng)\n",
    "\n",
    "df['rsid'] = arr1\n",
    "df['rp_name'] = arr2\n",
    "df['rs_name'] = arr3\n",
    "df['rkc'] = arr4\n",
    "df['rp_hier'] = arr5\n",
    "df['rsid_kc'] = arr6\n",
    "df['rsid_pname'] = arr7\n",
    "df['rsid_sname'] = arr8\n",
    "\n",
    "ans = df.loc[:,['rsid','rp_name','rs_name','rkc','rp_hier','rsid_kc','rsid_pname','rsid_sname']]\n",
    "ans.to_csv(\"data/train_rate.csv\",mode = 'a',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set rate fill(single feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_s(data1,data2,data3,leng,leng_t):\n",
    "    a = np.array(data1)\n",
    "    b = np.unique(a)\n",
    "\n",
    "    ans = dict.fromkeys(b,-1)\n",
    "    for i in range(0,leng):\n",
    "        if ans[data1[i]] == -1:\n",
    "            ans[data1[i]] = data2[i]\n",
    "    fea = []\n",
    "    for i in range(0,leng_t):\n",
    "        if data3[i] in ans:\n",
    "            fea.append(ans[data3[i]])\n",
    "        else:\n",
    "            fea.append(-1)\n",
    "    return fea"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set rate fill(multiple feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_d(data1,data2,data3,data4,data5,leng,leng_t):\n",
    "    ans = {}\n",
    "    for i in range(0,leng):\n",
    "        dummy = (data1[i],data2[i])\n",
    "        if dummy not in ans:\n",
    "            ans.setdefault(dummy,-1)\n",
    "\n",
    "    for i in range(0,leng):\n",
    "        dummy = (data1[i],data2[i])\n",
    "        if ans[dummy] == -1:\n",
    "            ans[dummy] = data3[i]\n",
    "    fea = []\n",
    "    for i in range(0,leng_t):\n",
    "        dummy = (data4[i],data5[i])\n",
    "        if dummy in ans:\n",
    "            fea.append(ans[dummy])\n",
    "        else:\n",
    "            fea.append(-1)\n",
    "    return fea"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set feature fill code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "major = pd.read_csv(\"data/train_select_str.csv\")\n",
    "rate = pd.read_csv(\"data/train_rate.csv\")\n",
    "test = pd.read_csv(\"data/test_index.csv\")\n",
    "\n",
    "sid = major[\"Anon Student Id\"]\n",
    "p_name = major[\"Problem Name\"]\n",
    "p_hier = major[\"Problem Hierarchy\"]\n",
    "s_name = major[\"Step Name\"]\n",
    "kc = major[\"KC(Default)\"]\n",
    "\n",
    "rsid = rate[\"rsid\"]\n",
    "rp_name = rate[\"rp_name\"]\n",
    "rp_hier = rate[\"rp_hier\"]\n",
    "rs_name = rate[\"rs_name\"]\n",
    "rkc = rate[\"rkc\"]\n",
    "rsid_kc = rate[\"rsid_kc\"]\n",
    "rsid_pname = rate[\"rsid_pname\"]\n",
    "rsid_sname = rate[\"rsid_sname\"]\n",
    "\n",
    "tsid = test[\"Anon Student Id\"]\n",
    "tp_name = test[\"Problem Name\"]\n",
    "tp_hier = test[\"Problem Hierarchy\"]\n",
    "ts_name = test[\"Step Name\"]\n",
    "tkc = test[\"KC(Default)\"]\n",
    "\n",
    "leng = len(sid)\n",
    "leng_t = len(tsid)\n",
    "\n",
    "test['rsid'] = test_s(sid,rsid,tsid,leng,leng_t)\n",
    "test['rp_name'] = test_s(p_name,rp_name,tp_name,leng,leng_t)\n",
    "test['rs_name'] = test_s(s_name,rs_name,ts_name,leng,leng_t)\n",
    "test['rkc'] = test_s(kc,rkc,tkc,leng,leng_t)\n",
    "test['rp_hier'] = test_s(p_hier,rp_hier,tp_hier,leng,leng_t)\n",
    "test['rsid_kc'] = test_d(sid,kc,rsid_kc,tsid,tkc,leng,leng_t)\n",
    "test['rsid_pname'] = test_d(sid,p_name,rsid_pname,tsid,tp_name,leng,leng_t)\n",
    "test['rsid_sname'] = test_d(sid,s_name,rsid_sname,tsid,ts_name,leng,leng_t)\n",
    "\n",
    "test.to_csv(\"data/test_rate_nan.csv\",mode = 'a',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set nan reset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_avr(col,leng):\n",
    "    num = 0\n",
    "    ans = 0\n",
    "    for i in range(0,leng):\n",
    "        if col[i] != -1:\n",
    "            num += 1\n",
    "            ans += col[i]\n",
    "    ans = round(ans/num,5)\n",
    "    for i in range(0,leng):\n",
    "        if col[i] == -1:\n",
    "            col[i] = ans\n",
    "    return col"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set nan reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\李宗泽\\AppData\\Local\\Temp\\ipykernel_1208\\3350195655.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col[i] = ans\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/test_rate_nan.csv\")\n",
    "\n",
    "leng = len(test[\"rsid\"])\n",
    "\n",
    "set_avr(test[\"rsid\"],leng)\n",
    "set_avr(test[\"rp_name\"],leng)\n",
    "set_avr(test[\"rp_hier\"],leng)\n",
    "set_avr(test[\"rs_name\"],leng)\n",
    "set_avr(test[\"rkc\"],leng)\n",
    "set_avr(test[\"rsid_kc\"],leng)\n",
    "set_avr(test[\"rsid_pname\"],leng)\n",
    "set_avr(test[\"rsid_sname\"],leng)\n",
    "\n",
    "test.to_csv(\"data/test_rate.csv\",mode = 'a',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three additional feature manipulation of trian data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/first_pro.csv\")\n",
    "\n",
    "opp = df[\"Opportunity(Default)\"]\n",
    "len_col = len(opp)\n",
    "\n",
    "dummy0 = [0] * len_col\n",
    "dummy1 = [0] * len_col\n",
    "dummy2 = [0] * len_col\n",
    "dummy3 = [0] * len_col\n",
    "\n",
    "for i in range(0,len_col):\n",
    "    if(type(opp[i]) == type('a')):\n",
    "        str_opp = opp[i].split('~~')\n",
    "        str_opp = [int(x) for x in str_opp]\n",
    "        l = len(str_opp)\n",
    "        \n",
    "        min_opp = min(str_opp)\n",
    "        avr = 0\n",
    "        for k in range(0,l):\n",
    "            avr += str_opp[k]\n",
    "        avr = round(avr / l,5)\n",
    "        if(l == 1):\n",
    "            dummy1[i] = l\n",
    "            dummy2[i] = min_opp\n",
    "            dummy3[i] = avr\n",
    "        if(l > 1):\n",
    "            for j in range(0,l):\n",
    "                if j == 0:\n",
    "                    dummy0[i] = str_opp[0]\n",
    "                    dummy1[i] = l\n",
    "                    dummy2[i] = min_opp\n",
    "                    dummy3[i] = avr\n",
    "                else:\n",
    "                    dummy0.append(str_opp[j])\n",
    "                    dummy1.append(l)\n",
    "                    dummy2.append(min_opp)\n",
    "                    dummy3.append(avr)\n",
    "\n",
    "ans = pd.DataFrame({'Opportunity(Default)':dummy0,'kc_num':dummy1,'min_opp':dummy2,'mean_opp':dummy3})\n",
    "ans.to_csv(r\"data/train_additional_rate.csv\",mode = 'a',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three additional feature manipulation of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "1500\n",
      "1500\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/first_pro_test.csv\")\n",
    "\n",
    "opp = df[\"Opportunity(Default)\"]\n",
    "len_col = len(opp)\n",
    "\n",
    "dummy0 = [0] * len_col\n",
    "dummy1 = [0] * len_col\n",
    "dummy2 = [0] * len_col\n",
    "dummy3 = [0] * len_col\n",
    "\n",
    "for i in range(0,len_col):\n",
    "    if(type(opp[i]) == type('a')):\n",
    "        str_opp = opp[i].split('~~')\n",
    "        str_opp = [int(x) for x in str_opp]\n",
    "        l = len(str_opp)\n",
    "        \n",
    "        min_opp = min(str_opp)\n",
    "        avr = 0\n",
    "        for k in range(0,l):\n",
    "            avr += str_opp[k]\n",
    "        avr = round(avr / l,5)\n",
    "        if(l == 1):\n",
    "            dummy1[i] = l\n",
    "            dummy2[i] = min_opp\n",
    "            dummy3[i] = avr\n",
    "        if(l > 1):\n",
    "            for j in range(0,l):\n",
    "                if j == 0:\n",
    "                    dummy0[i] = str_opp[0]\n",
    "                    dummy1[i] = l\n",
    "                    dummy2[i] = min_opp\n",
    "                    dummy3[i] = avr\n",
    "                else:\n",
    "                    dummy0.append(str_opp[j])\n",
    "                    dummy1.append(l)\n",
    "                    dummy2.append(min_opp)\n",
    "                    dummy3.append(avr)\n",
    "\n",
    "ans = pd.DataFrame({'Opportunity(Default)':dummy0,'kc_num':dummy1,'min_opp':dummy2,'mean_opp':dummy3})\n",
    "ans.to_csv(r\"data/test_additional_rate.csv\",mode = 'a',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f21bb2d5c565dbc33d815445cee0d4e3f2f7951520fd8c0e3b4200672f41bfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
